{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "051b18c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec901a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "connection = pymysql.connect(host='127.0.0.1',user='root',passwd='12345678',database = \"github\",cursorclass=pymysql.cursors.DictCursor)\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fcc34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "GITHUB_TOKEN = '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'\n",
    "HEADERS = {\n",
    "    'Authorization': f'token {GITHUB_TOKEN}',\n",
    "    'Accept': 'application/vnd.github.v3+json'\n",
    "}\n",
    "\n",
    "topics = [\"machine learning\", \"data visualization\", \"deep learning\", \n",
    "          \"natural language processing\", \"data science\", \"AI\", \n",
    "          \"big data\", \"data engineering\", \"reinforcement learning\", \n",
    "          \"data mining\"]\n",
    "\n",
    "SEARCH_URL = \"https://api.github.com/search/repositories\"\n",
    "\n",
    "def search_repositories(topic, max_repos=1000):\n",
    "    per_page = 100\n",
    "    repo_data = []\n",
    "    page = 1\n",
    "\n",
    "    while len(repo_data) < max_repos:\n",
    "        params = {\n",
    "            'q': topic,\n",
    "            'sort': 'stars',\n",
    "            'order': 'desc',\n",
    "            'per_page': per_page,\n",
    "            'page': page\n",
    "        }\n",
    "        \n",
    "        response = requests.get(SEARCH_URL, headers=HEADERS, params=params)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch repositories for topic {topic}: {response.status_code}\")\n",
    "            break\n",
    "        \n",
    "        repositories = response.json().get('items', [])\n",
    "\n",
    "        if not repositories:\n",
    "            break\n",
    "        \n",
    "        for repo in repositories:\n",
    "            repo_info = {\n",
    "                \"Repository Name\": repo.get(\"name\"),\n",
    "                \"Owner\": repo.get(\"owner\", {}).get(\"login\"),\n",
    "                \"Description\": repo.get(\"description\"),\n",
    "                \"URL\": repo.get(\"html_url\"),\n",
    "                \"Programming Language\": repo.get(\"language\"),\n",
    "                \"Creation Date\": repo.get(\"created_at\"),\n",
    "                \"Last Updated Date\": repo.get(\"updated_at\"),\n",
    "                \"Number of Stars\": repo.get(\"stargazers_count\"),\n",
    "                \"Number of Forks\": repo.get(\"forks_count\"),\n",
    "                \"Number of Open Issues\": repo.get(\"open_issues_count\"),\n",
    "                \"License Type\": repo.get(\"license\", {}).get(\"name\") if repo.get(\"license\") else \"No license\"\n",
    "            }\n",
    "            repo_data.append(repo_info)\n",
    "\n",
    "        if len(repositories) < per_page:\n",
    "            break\n",
    "\n",
    "        page += 1\n",
    "\n",
    "    return repo_data[:max_repos]\n",
    "\n",
    "def extract_trending_repo_data(topics, max_repos=1000):\n",
    "    all_repo_data = {}\n",
    "    for topic in topics:\n",
    "        repos = search_repositories(topic, max_repos)\n",
    "        all_repo_data[topic] = repos\n",
    "    return all_repo_data\n",
    "\n",
    "trending_repo_data = extract_trending_repo_data(topics, max_repos=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b9f55cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in topics:\n",
    "    for k in range(0,1000):\n",
    "        topic = i\n",
    "        r_name = trending_repo_data[i][k]['Repository Name']\n",
    "        r_owner = trending_repo_data[i][k]['Owner']\n",
    "        r_description = trending_repo_data[i][k]['Description']\n",
    "        url = trending_repo_data[i][k]['URL']\n",
    "        pro_language = trending_repo_data[i][k]['Programming Language']\n",
    "        creation_date = datetime.strptime(trending_repo_data[i][k]['Creation Date'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "        last_update = datetime.strptime(trending_repo_data[i][k]['Last Updated Date'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "        star_count = trending_repo_data[i][k]['Number of Stars']\n",
    "        fork_count = trending_repo_data[i][k]['Number of Forks']\n",
    "        issue_count = trending_repo_data[i][k]['Number of Open Issues']\n",
    "        license_type = trending_repo_data[i][k]['License Type']\n",
    "        \n",
    "        data.append([topic, r_name, r_owner, r_description, url, pro_language, creation_date,\n",
    "                     last_update, star_count, fork_count, issue_count, license_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3d95454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=[\n",
    "    'topic', 'r_name', 'r_owner', 'r_description', 'url', 'pro_language', 'creation_date',\n",
    "    'last_update', 'star_count', 'fork_count', 'issue_count', 'license_type'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f3b66fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pro_language'].fillna(\"Text/Book/Q&A\",inplace = True)\n",
    "df['r_description'].fillna(\"None\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "629b742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='127.0.0.1',user='root',passwd='12345678',database = 'github' ,cursorclass=pymysql.cursors.DictCursor)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "create_table_query = '''\n",
    "CREATE TABLE IF NOT EXISTS github (\n",
    "    topic TEXT,\n",
    "    r_name TEXT,\n",
    "    r_owner TEXT,\n",
    "    r_description MEDIUMTEXT,\n",
    "    url TEXT,\n",
    "    pro_language TEXT,\n",
    "    creation_date TIMESTAMP,\n",
    "    last_update TIMESTAMP,\n",
    "    star_count INT,\n",
    "    fork_count INT,\n",
    "    issue_count INT,\n",
    "    license_type TEXT\n",
    ");\n",
    "'''\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    insert_query = '''\n",
    "    INSERT INTO github (topic, r_name, r_owner, r_description, url, pro_language, \n",
    "                        creation_date, last_update, star_count, fork_count, issue_count, license_type)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    '''\n",
    "    cursor.execute(insert_query, tuple(row))\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
